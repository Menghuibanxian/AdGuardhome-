#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AdGuard Home è‡ªå®šä¹‰è®¾å¤‡æ—¥å¿—æŠ“å–å·¥å…·
æ”¯æŒIPv4å’ŒIPv6è®¾å¤‡æ—¥å¿—æŠ“å–ä¸ç½‘å€ç»Ÿè®¡
"""

import requests
import json
import sys
from collections import defaultdict
from urllib.parse import urlparse
import argparse

class AdGuardLogFetcher:
    def __init__(self, base_url, username, password):
        self.base_url = base_url.rstrip('/')
        self.session = requests.Session()
        self.session.auth = (username, password)
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
    
    def login(self):
        """ç™»å½•åˆ°AdGuard Home"""
        try:
            response = self.session.get(f"{self.base_url}/control/status", timeout=10)
            if response.status_code == 200:
                print("âœ… æˆåŠŸè¿æ¥åˆ° AdGuard Home")
                return True
            else:
                print(f"âŒ è¿æ¥å¤±è´¥: {response.status_code}")
                return False
        except Exception as e:
            print(f"âŒ è¿æ¥é”™è¯¯: {str(e)}")
            return False
    
    def get_query_log(self, limit=1000):
        """è·å–æŸ¥è¯¢æ—¥å¿—"""
        try:
            params = {
                'limit': limit
            }
            response = self.session.get(f"{self.base_url}/control/querylog", params=params, timeout=30)
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ è·å–æ—¥å¿—å¤±è´¥: {response.status_code}")
                return None
        except Exception as e:
            print(f"âŒ è·å–æ—¥å¿—é”™è¯¯: {str(e)}")
            return None
    
    def filter_logs_by_client(self, logs, client_ips):
        """æ ¹æ®å®¢æˆ·ç«¯IPåœ°å€è¿‡æ»¤æ—¥å¿—"""
        if not logs or 'data' not in logs:
            return []
        
        filtered_logs = []
        for entry in logs['data']:
            client_ip = entry.get('client', '')
            if client_ip in client_ips:
                filtered_logs.append(entry)
        
        return filtered_logs
    
    def extract_domains_and_count(self, logs):
        """æå–åŸŸåå¹¶ç»Ÿè®¡å‡ºç°æ¬¡æ•°"""
        domain_count = defaultdict(int)
        
        for entry in logs:
            domain = entry.get('question', {}).get('name', '')
            if domain:
                # ç§»é™¤æœ«å°¾çš„ç‚¹
                domain = domain.rstrip('.')
                domain_count[domain] += 1
        
        return dict(domain_count)
    
    def save_to_txt(self, domain_count, filename="domain_stats.txt"):
        """ä¿å­˜ç»“æœåˆ°æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                for domain, count in sorted(domain_count.items(), key=lambda x: x[1], reverse=True):
                    f.write(f"{domain} {count}\n")
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ° {filename}")
            return filename
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
            return None

def main():
    parser = argparse.ArgumentParser(description='AdGuard Home è‡ªå®šä¹‰è®¾å¤‡æ—¥å¿—æŠ“å–å·¥å…·')
    parser.add_argument('--url', default='http://192.168.100.1:8008', help='AdGuard Home åœ°å€')
    parser.add_argument('--username', default='root', help='ç”¨æˆ·å')
    parser.add_argument('--password', default='du13280325005', help='å¯†ç ')
    parser.add_argument('--clients', required=True, help='å®¢æˆ·ç«¯IPåœ°å€ï¼Œå¤šä¸ªç”¨é€—å·åˆ†éš”')
    parser.add_argument('--limit', type=int, default=1000, help='æ—¥å¿—æ¡æ•°é™åˆ¶')
    parser.add_argument('--output', default='domain_stats.txt', help='è¾“å‡ºæ–‡ä»¶å')
    
    args = parser.parse_args()
    
    # è§£æå®¢æˆ·ç«¯IPåˆ—è¡¨
    client_ips = [ip.strip() for ip in args.clients.split(',') if ip.strip()]
    if not client_ips:
        print("âŒ è¯·æä¾›æœ‰æ•ˆçš„å®¢æˆ·ç«¯IPåœ°å€")
        return
    
    print(f"ğŸ” å¼€å§‹æŠ“å– AdGuard Home æ—¥å¿—...")
    print(f"ğŸŒ AdGuard åœ°å€: {args.url}")
    print(f"ğŸ‘¤ ç”¨æˆ·å: {args.username}")
    print(f"ğŸ’» å®¢æˆ·ç«¯IP: {', '.join(client_ips)}")
    
    # åˆ›å»ºæŠ“å–å™¨å®ä¾‹
    fetcher = AdGuardLogFetcher(args.url, args.username, args.password)
    
    # ç™»å½•
    if not fetcher.login():
        return
    
    # è·å–æ—¥å¿—
    print("ğŸ“¥ æ­£åœ¨è·å–æŸ¥è¯¢æ—¥å¿—...")
    logs = fetcher.get_query_log(args.limit)
    if not logs:
        return
    
    # è¿‡æ»¤æ—¥å¿—
    print("FilterWhere æ­£åœ¨æ ¹æ®å®¢æˆ·ç«¯IPè¿‡æ»¤æ—¥å¿—...")
    filtered_logs = fetcher.filter_logs_by_client(logs, client_ips)
    print(f"ğŸ“Š è¿‡æ»¤åå¾—åˆ° {len(filtered_logs)} æ¡è®°å½•")
    
    if not filtered_logs:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®°å½•")
        return
    
    # ç»Ÿè®¡åŸŸå
    print("ğŸ“ˆ æ­£åœ¨ç»Ÿè®¡åŸŸåå‡ºç°æ¬¡æ•°...")
    domain_count = fetcher.extract_domains_and_count(filtered_logs)
    print(f"ğŸ“‹ å…±ç»Ÿè®¡åˆ° {len(domain_count)} ä¸ªä¸åŒåŸŸå")
    
    # ä¿å­˜ç»“æœ
    filename = fetcher.save_to_txt(domain_count, args.output)
    if filename:
        print(f"ğŸ‰ ä»»åŠ¡å®Œæˆï¼ç»“æœæ–‡ä»¶: {filename}")
        print("\nğŸ“Š å‰10ä¸ªè®¿é—®æœ€å¤šçš„åŸŸå:")
        for i, (domain, count) in enumerate(sorted(domain_count.items(), key=lambda x: x[1], reverse=True)[:10], 1):
            print(f"  {i:2d}. {domain:<30} ({count} æ¬¡)")

if __name__ == "__main__":
    main()